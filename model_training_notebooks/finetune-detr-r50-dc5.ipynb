{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-05T02:55:06.977137Z",
     "iopub.status.busy": "2024-11-05T02:55:06.976315Z",
     "iopub.status.idle": "2024-11-05T02:55:22.649873Z",
     "shell.execute_reply": "2024-11-05T02:55:22.648747Z",
     "shell.execute_reply.started": "2024-11-05T02:55:06.977096Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets transformers accelerate timm albumentations>=1.4.5 torchmetrics pycocotools coco-eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T02:55:25.749710Z",
     "iopub.status.busy": "2024-11-05T02:55:25.749278Z",
     "iopub.status.idle": "2024-11-05T02:55:47.120069Z",
     "shell.execute_reply": "2024-11-05T02:55:47.119238Z",
     "shell.execute_reply.started": "2024-11-05T02:55:25.749669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers.image_transforms import center_to_corners_format\n",
    "from transformers import AutoModelForObjectDetection, TrainingArguments, Trainer, DetrImageProcessor, DetrForObjectDetection\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "import torch\n",
    "from functools import partial\n",
    "from coco_eval import CocoEvaluator\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T02:56:01.871998Z",
     "iopub.status.busy": "2024-11-05T02:56:01.870886Z",
     "iopub.status.idle": "2024-11-05T02:56:01.875937Z",
     "shell.execute_reply": "2024-11-05T02:56:01.874988Z",
     "shell.execute_reply.started": "2024-11-05T02:56:01.871957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"facebook/detr-resnet-50-dc5\"\n",
    "IMAGE_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T02:56:05.021007Z",
     "iopub.status.busy": "2024-11-05T02:56:05.020609Z",
     "iopub.status.idle": "2024-11-05T02:56:05.028732Z",
     "shell.execute_reply": "2024-11-05T02:56:05.027665Z",
     "shell.execute_reply.started": "2024-11-05T02:56:05.020973Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "    def __init__(self, img_folder, processor):\n",
    "        ann_file = os.path.join(img_folder, \"_annotations.coco.json\")\n",
    "        super(CocoDetection, self).__init__(img_folder, ann_file)\n",
    "        self.processor = processor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # read in PIL image and target in COCO format\n",
    "        # feel free to add data augmentation here before passing them to the next step\n",
    "        img, target = super(CocoDetection, self).__getitem__(idx)\n",
    "\n",
    "        # preprocess image and target (converting target to DETR format, resizing + normalization of both image and target)\n",
    "        image_id = self.ids[idx]\n",
    "        target = {'image_id': image_id, 'annotations': target}\n",
    "        encoding = self.processor(images=img, annotations=target, return_tensors=\"pt\")\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze() # remove batch dimension\n",
    "        target = encoding[\"labels\"][0] # remove batch dimension\n",
    "\n",
    "        return pixel_values, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T02:56:08.965259Z",
     "iopub.status.busy": "2024-11-05T02:56:08.964872Z",
     "iopub.status.idle": "2024-11-05T02:56:08.989116Z",
     "shell.execute_reply": "2024-11-05T02:56:08.988050Z",
     "shell.execute_reply.started": "2024-11-05T02:56:08.965225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    pixel_values = [item[0] for item in batch]\n",
    "    encoding = processor.pad(pixel_values, return_tensors=\"pt\")\n",
    "    labels = [item[1] for item in batch]\n",
    "    batch = {}\n",
    "    batch['pixel_values'] = encoding['pixel_values']\n",
    "    batch['pixel_mask'] = encoding['pixel_mask']\n",
    "    batch['labels'] = labels\n",
    "    return batch\n",
    "\n",
    "def convert_bbox_yolo_to_pascal(boxes, image_size):\n",
    "    \"\"\"\n",
    "    Convert bounding boxes from YOLO format (x_center, y_center, width, height) in range [0, 1]\n",
    "    to Pascal VOC format (x_min, y_min, x_max, y_max) in absolute coordinates.\n",
    "\n",
    "    Args:\n",
    "        boxes (torch.Tensor): Bounding boxes in YOLO format\n",
    "        image_size (Tuple[int, int]): Image size in format (height, width)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Bounding boxes in Pascal VOC format (x_min, y_min, x_max, y_max)\n",
    "    \"\"\"\n",
    "    # convert center to corners format\n",
    "    boxes = center_to_corners_format(boxes)\n",
    "\n",
    "    # convert to absolute coordinates\n",
    "    height, width = image_size\n",
    "    boxes = boxes * torch.tensor([[width, height, width, height]])\n",
    "\n",
    "    return boxes\n",
    "\n",
    "@dataclass\n",
    "class ModelOutput:\n",
    "    logits: torch.Tensor\n",
    "    pred_boxes: torch.Tensor\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_metrics(evaluation_results, image_processor, threshold=0.0, id2label=None):\n",
    "    \"\"\"\n",
    "    Compute mean average mAP, mAR and their variants for the object detection task.\n",
    "\n",
    "    Args:\n",
    "        evaluation_results (EvalPrediction): Predictions and targets from evaluation.\n",
    "        threshold (float, optional): Threshold to filter predicted boxes by confidence. Defaults to 0.0.\n",
    "        id2label (Optional[dict], optional): Mapping from class id to class name. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Mapping[str, float]: Metrics in a form of dictionary {<metric_name>: <metric_value>}\n",
    "    \"\"\"\n",
    "\n",
    "    predictions, targets = evaluation_results.predictions, evaluation_results.label_ids\n",
    "\n",
    "    # For metric computation we need to provide:\n",
    "    #  - targets in a form of list of dictionaries with keys \"boxes\", \"labels\"\n",
    "    #  - predictions in a form of list of dictionaries with keys \"boxes\", \"scores\", \"labels\"\n",
    "\n",
    "    image_sizes = []\n",
    "    post_processed_targets = []\n",
    "    post_processed_predictions = []\n",
    "\n",
    "    # Collect targets in the required format for metric computation\n",
    "    for batch in targets:\n",
    "        # collect image sizes, we will need them for predictions post processing\n",
    "        batch_image_sizes = torch.tensor(np.array([x[\"orig_size\"] for x in batch]))\n",
    "        image_sizes.append(batch_image_sizes)\n",
    "        # collect targets in the required format for metric computation\n",
    "        # boxes were converted to YOLO format needed for model training\n",
    "        # here we will convert them to Pascal VOC format (x_min, y_min, x_max, y_max)\n",
    "        for image_target in batch:\n",
    "            boxes = torch.tensor(image_target[\"boxes\"])\n",
    "            boxes = convert_bbox_yolo_to_pascal(boxes, image_target[\"orig_size\"])\n",
    "            labels = torch.tensor(image_target[\"class_labels\"])\n",
    "            post_processed_targets.append({\"boxes\": boxes, \"labels\": labels})\n",
    "\n",
    "    # Collect predictions in the required format for metric computation,\n",
    "    # model produce boxes in YOLO format, then image_processor convert them to Pascal VOC format\n",
    "    for batch, target_sizes in zip(predictions, image_sizes):\n",
    "        batch_logits, batch_boxes = batch[1], batch[2]\n",
    "        output = ModelOutput(logits=torch.tensor(batch_logits), pred_boxes=torch.tensor(batch_boxes))\n",
    "        post_processed_output = image_processor.post_process_object_detection(\n",
    "            output, threshold=threshold, target_sizes=target_sizes\n",
    "        )\n",
    "        post_processed_predictions.extend(post_processed_output)\n",
    "\n",
    "    # Compute metrics\n",
    "    metric = MeanAveragePrecision(box_format=\"xyxy\", class_metrics=True)\n",
    "    metric.update(post_processed_predictions, post_processed_targets)\n",
    "    metrics = metric.compute()\n",
    "\n",
    "    # Replace list of per class metrics with separate metric for each class\n",
    "    classes = metrics.pop(\"classes\")\n",
    "    map_per_class = metrics.pop(\"map_per_class\")\n",
    "    mar_100_per_class = metrics.pop(\"mar_100_per_class\")\n",
    "    if classes.ndim > 0 and map_per_class.ndim > 0 and mar_100_per_class.ndim > 0:\n",
    "        for class_id, class_map, class_mar in zip(classes, map_per_class, mar_100_per_class):\n",
    "            class_name = id2label[class_id.item()] if id2label is not None else class_id.item()\n",
    "            metrics[f\"map_{class_name}\"] = class_map\n",
    "            metrics[f\"mar_100_{class_name}\"] = class_mar\n",
    "    else:\n",
    "        class_name = id2label[classes.item()] if id2label is not None else classes.item()\n",
    "        metrics[f\"map_{class_name}\"] = map_per_class\n",
    "        metrics[f\"mar_100_{class_name}\"] = mar_100_per_class\n",
    "\n",
    "    metrics = {k: round(v.item(), 4) for k, v in metrics.items()}\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def convert_to_xywh(boxes):\n",
    "    xmin, ymin, xmax, ymax = boxes.unbind(1)\n",
    "    return torch.stack((xmin, ymin, xmax - xmin, ymax - ymin), dim=1)\n",
    "\n",
    "def prepare_for_coco_detection(predictions):\n",
    "    coco_results = []\n",
    "    for original_id, prediction in predictions.items():\n",
    "        if len(prediction) == 0:\n",
    "            continue\n",
    "\n",
    "        boxes = prediction[\"boxes\"]\n",
    "        boxes = convert_to_xywh(boxes).tolist()\n",
    "        scores = prediction[\"scores\"].tolist()\n",
    "        labels = prediction[\"labels\"].tolist()\n",
    "\n",
    "        coco_results.extend(\n",
    "            [\n",
    "                {\n",
    "                    \"image_id\": original_id,\n",
    "                    \"category_id\": labels[k],\n",
    "                    \"bbox\": box,\n",
    "                    \"score\": scores[k],\n",
    "                }\n",
    "                for k, box in enumerate(boxes)\n",
    "            ]\n",
    "        )\n",
    "    return coco_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T02:56:40.509299Z",
     "iopub.status.busy": "2024-11-05T02:56:40.508897Z",
     "iopub.status.idle": "2024-11-05T02:56:41.160952Z",
     "shell.execute_reply": "2024-11-05T02:56:41.160049Z",
     "shell.execute_reply.started": "2024-11-05T02:56:40.509262Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b4b46442824643a68659c411b0b375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/274 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Number of training examples: 2417\n",
      "Number of validation examples: 117\n",
      "{0: 'lung_ct', 1: 'nodule'}\n",
      "{'lung_ct': 0, 'nodule': 1}\n"
     ]
    }
   ],
   "source": [
    "processor = DetrImageProcessor.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    do_resize=True,\n",
    "    # size={\"height\": IMAGE_SIZE, \"width\": IMAGE_SIZE}\n",
    "    size={\"max_height\": IMAGE_SIZE, \"max_width\": IMAGE_SIZE},\n",
    ")\n",
    "\n",
    "train_dataset = CocoDetection(img_folder='/kaggle/input/lung-ct-version-n-512/lung_ct_version_n_512.v2i.coco/train', processor=processor)\n",
    "val_dataset = CocoDetection(img_folder='/kaggle/input/lung-ct-version-n-512/lung_ct_version_n_512.v2i.coco/valid', processor=processor)\n",
    "\n",
    "cats = train_dataset.coco.cats\n",
    "id2label = {k: v['name'] for k,v in cats.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(val_dataset))\n",
    "print(id2label)\n",
    "print(label2id)\n",
    "\n",
    "eval_compute_metrics_fn = partial(\n",
    "    compute_metrics, image_processor=processor, id2label=id2label, threshold=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T02:56:45.160708Z",
     "iopub.status.busy": "2024-11-05T02:56:45.159817Z",
     "iopub.status.idle": "2024-11-05T02:56:48.772452Z",
     "shell.execute_reply": "2024-11-05T02:56:48.771665Z",
     "shell.execute_reply.started": "2024-11-05T02:56:45.160654Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95553ebf12f245d3add918d389d2831d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414986f9cd94481180c363031e864521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99fab156b7944cd0ad396be427088488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50-dc5 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at facebook/detr-resnet-50-dc5 and are newly initialized because the shapes did not match:\n",
      "- class_labels_classifier.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- class_labels_classifier.weight: found shape torch.Size([92, 256]) in the checkpoint and torch.Size([3, 256]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DetrForObjectDetection.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    num_labels=len(id2label),\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"finetune_detr_r50_dc5_version\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=50,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    weight_decay=1e-4,\n",
    "    max_grad_norm=0.01,\n",
    "    fp16=False,\n",
    "    metric_for_best_model=\"eval_map\",\n",
    "    load_best_model_at_end=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    eval_do_concat_batches=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=eval_compute_metrics_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T02:56:59.941491Z",
     "iopub.status.busy": "2024-11-05T02:56:59.940568Z",
     "iopub.status.idle": "2024-11-05T05:38:12.375077Z",
     "shell.execute_reply": "2024-11-05T05:38:12.374142Z",
     "shell.execute_reply.started": "2024-11-05T02:56:59.941451Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97518f56d0d466083fdb2d8233039f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111539638888909, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241105_025707-bzy02g8e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/huynhduykhoi9166/huggingface/runs/bzy02g8e' target=\"_blank\">finetune_detr_r50_dc5_version</a></strong> to <a href='https://wandb.ai/huynhduykhoi9166/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/huynhduykhoi9166/huggingface' target=\"_blank\">https://wandb.ai/huynhduykhoi9166/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/huynhduykhoi9166/huggingface/runs/bzy02g8e' target=\"_blank\">https://wandb.ai/huynhduykhoi9166/huggingface/runs/bzy02g8e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15150' max='15150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15150/15150 2:40:58, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Map 50</th>\n",
       "      <th>Map 75</th>\n",
       "      <th>Map Small</th>\n",
       "      <th>Map Medium</th>\n",
       "      <th>Map Large</th>\n",
       "      <th>Mar 1</th>\n",
       "      <th>Mar 10</th>\n",
       "      <th>Mar 100</th>\n",
       "      <th>Mar Small</th>\n",
       "      <th>Mar Medium</th>\n",
       "      <th>Mar Large</th>\n",
       "      <th>Map Nodule</th>\n",
       "      <th>Mar 100 Nodule</th>\n",
       "      <th>Map Lung Ct</th>\n",
       "      <th>Mar 100 Lung Ct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.595221</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.058800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>0.366700</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.779000</td>\n",
       "      <td>1.097074</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.213600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.175200</td>\n",
       "      <td>0.377800</td>\n",
       "      <td>0.368800</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.377800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.779000</td>\n",
       "      <td>1.096096</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.186600</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.059400</td>\n",
       "      <td>0.273700</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>0.371800</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.371800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.152800</td>\n",
       "      <td>0.933990</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.293700</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>0.451500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.229900</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.458100</td>\n",
       "      <td>0.447700</td>\n",
       "      <td>0.611100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.458100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.013400</td>\n",
       "      <td>1.135004</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.286300</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.397900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.315400</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>0.314700</td>\n",
       "      <td>0.566700</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.331600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.013400</td>\n",
       "      <td>1.044507</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.207300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.510300</td>\n",
       "      <td>0.507300</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.510300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.989500</td>\n",
       "      <td>0.886797</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>0.448200</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.206800</td>\n",
       "      <td>0.381200</td>\n",
       "      <td>0.478600</td>\n",
       "      <td>0.468800</td>\n",
       "      <td>0.644400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.478600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.989500</td>\n",
       "      <td>0.967454</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.403800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.134200</td>\n",
       "      <td>0.349600</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>0.412800</td>\n",
       "      <td>0.633300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.927100</td>\n",
       "      <td>0.821370</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.562200</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.219800</td>\n",
       "      <td>0.468300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.279500</td>\n",
       "      <td>0.445300</td>\n",
       "      <td>0.538500</td>\n",
       "      <td>0.526600</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.538500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.891700</td>\n",
       "      <td>0.879487</td>\n",
       "      <td>0.208700</td>\n",
       "      <td>0.556200</td>\n",
       "      <td>0.155500</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>0.445300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.274400</td>\n",
       "      <td>0.424800</td>\n",
       "      <td>0.494900</td>\n",
       "      <td>0.480700</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.208700</td>\n",
       "      <td>0.494900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.891700</td>\n",
       "      <td>0.905108</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.576100</td>\n",
       "      <td>0.124600</td>\n",
       "      <td>0.213900</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.374400</td>\n",
       "      <td>0.473500</td>\n",
       "      <td>0.464200</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.473500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.867900</td>\n",
       "      <td>0.890634</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>0.521900</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>0.509300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.417100</td>\n",
       "      <td>0.478600</td>\n",
       "      <td>0.474300</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>0.478600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.867900</td>\n",
       "      <td>0.790947</td>\n",
       "      <td>0.278900</td>\n",
       "      <td>0.580900</td>\n",
       "      <td>0.220600</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.448300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.490600</td>\n",
       "      <td>0.582900</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>0.633300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.278900</td>\n",
       "      <td>0.582900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.844200</td>\n",
       "      <td>0.846444</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.576300</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>0.434500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.283800</td>\n",
       "      <td>0.416200</td>\n",
       "      <td>0.492300</td>\n",
       "      <td>0.479800</td>\n",
       "      <td>0.644400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.492300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.798800</td>\n",
       "      <td>0.835241</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.571400</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>0.214200</td>\n",
       "      <td>0.271900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.269200</td>\n",
       "      <td>0.415400</td>\n",
       "      <td>0.533300</td>\n",
       "      <td>0.524800</td>\n",
       "      <td>0.644400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.533300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.798800</td>\n",
       "      <td>0.798411</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.609300</td>\n",
       "      <td>0.136200</td>\n",
       "      <td>0.256600</td>\n",
       "      <td>0.535200</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.314500</td>\n",
       "      <td>0.440200</td>\n",
       "      <td>0.504300</td>\n",
       "      <td>0.486200</td>\n",
       "      <td>0.733300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.504300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.745100</td>\n",
       "      <td>0.705825</td>\n",
       "      <td>0.337700</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.247600</td>\n",
       "      <td>0.328700</td>\n",
       "      <td>0.554400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.374400</td>\n",
       "      <td>0.504300</td>\n",
       "      <td>0.552100</td>\n",
       "      <td>0.543100</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.337700</td>\n",
       "      <td>0.552100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.745100</td>\n",
       "      <td>0.797739</td>\n",
       "      <td>0.299100</td>\n",
       "      <td>0.701300</td>\n",
       "      <td>0.195500</td>\n",
       "      <td>0.284800</td>\n",
       "      <td>0.648200</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.362400</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.502800</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.299100</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.744500</td>\n",
       "      <td>0.692546</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.681100</td>\n",
       "      <td>0.354700</td>\n",
       "      <td>0.342700</td>\n",
       "      <td>0.600500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>0.528200</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>0.559600</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>0.741540</td>\n",
       "      <td>0.353600</td>\n",
       "      <td>0.747300</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.341800</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.381200</td>\n",
       "      <td>0.496600</td>\n",
       "      <td>0.553800</td>\n",
       "      <td>0.542200</td>\n",
       "      <td>0.722200</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.353600</td>\n",
       "      <td>0.553800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>0.785878</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.729300</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.299000</td>\n",
       "      <td>0.583300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.365800</td>\n",
       "      <td>0.436800</td>\n",
       "      <td>0.484600</td>\n",
       "      <td>0.468800</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.484600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.744503</td>\n",
       "      <td>0.326300</td>\n",
       "      <td>0.727300</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.628800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.371800</td>\n",
       "      <td>0.483800</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>0.533000</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.326300</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.827384</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.213300</td>\n",
       "      <td>0.266200</td>\n",
       "      <td>0.649100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.436800</td>\n",
       "      <td>0.517100</td>\n",
       "      <td>0.498200</td>\n",
       "      <td>0.755600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>0.517100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.737781</td>\n",
       "      <td>0.338100</td>\n",
       "      <td>0.740100</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.598300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.372600</td>\n",
       "      <td>0.482900</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>0.533000</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.338100</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.654600</td>\n",
       "      <td>0.728397</td>\n",
       "      <td>0.355200</td>\n",
       "      <td>0.804300</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.341100</td>\n",
       "      <td>0.597000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.417100</td>\n",
       "      <td>0.500900</td>\n",
       "      <td>0.564100</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.355200</td>\n",
       "      <td>0.564100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.654600</td>\n",
       "      <td>0.787673</td>\n",
       "      <td>0.290200</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.592500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.359800</td>\n",
       "      <td>0.446200</td>\n",
       "      <td>0.541900</td>\n",
       "      <td>0.527500</td>\n",
       "      <td>0.722200</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.290200</td>\n",
       "      <td>0.541900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.631600</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.643900</td>\n",
       "      <td>0.193300</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.659400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.355600</td>\n",
       "      <td>0.454700</td>\n",
       "      <td>0.538500</td>\n",
       "      <td>0.522000</td>\n",
       "      <td>0.777800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.538500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.631600</td>\n",
       "      <td>0.714343</td>\n",
       "      <td>0.363700</td>\n",
       "      <td>0.734000</td>\n",
       "      <td>0.324900</td>\n",
       "      <td>0.349600</td>\n",
       "      <td>0.591200</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.421400</td>\n",
       "      <td>0.518800</td>\n",
       "      <td>0.576100</td>\n",
       "      <td>0.569700</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.363700</td>\n",
       "      <td>0.576100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.619000</td>\n",
       "      <td>0.782760</td>\n",
       "      <td>0.285100</td>\n",
       "      <td>0.701400</td>\n",
       "      <td>0.140700</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>0.467800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.539300</td>\n",
       "      <td>0.525700</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.285100</td>\n",
       "      <td>0.539300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.612700</td>\n",
       "      <td>0.678873</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.767400</td>\n",
       "      <td>0.303100</td>\n",
       "      <td>0.350800</td>\n",
       "      <td>0.668700</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.422200</td>\n",
       "      <td>0.527400</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>0.584400</td>\n",
       "      <td>0.733300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.612700</td>\n",
       "      <td>0.716936</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.757700</td>\n",
       "      <td>0.263900</td>\n",
       "      <td>0.329300</td>\n",
       "      <td>0.598300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.374400</td>\n",
       "      <td>0.496600</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>0.530300</td>\n",
       "      <td>0.722200</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.594400</td>\n",
       "      <td>0.695441</td>\n",
       "      <td>0.370300</td>\n",
       "      <td>0.758200</td>\n",
       "      <td>0.303300</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>0.645900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.404300</td>\n",
       "      <td>0.514500</td>\n",
       "      <td>0.578600</td>\n",
       "      <td>0.565100</td>\n",
       "      <td>0.755600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.370300</td>\n",
       "      <td>0.578600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.594400</td>\n",
       "      <td>0.671842</td>\n",
       "      <td>0.401100</td>\n",
       "      <td>0.803300</td>\n",
       "      <td>0.317600</td>\n",
       "      <td>0.385500</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.453800</td>\n",
       "      <td>0.540200</td>\n",
       "      <td>0.588000</td>\n",
       "      <td>0.575200</td>\n",
       "      <td>0.755600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.401100</td>\n",
       "      <td>0.588000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.578800</td>\n",
       "      <td>0.703543</td>\n",
       "      <td>0.393500</td>\n",
       "      <td>0.790700</td>\n",
       "      <td>0.297800</td>\n",
       "      <td>0.383700</td>\n",
       "      <td>0.716600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.429900</td>\n",
       "      <td>0.522200</td>\n",
       "      <td>0.565800</td>\n",
       "      <td>0.548600</td>\n",
       "      <td>0.788900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.393500</td>\n",
       "      <td>0.565800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.557200</td>\n",
       "      <td>0.657704</td>\n",
       "      <td>0.400700</td>\n",
       "      <td>0.779600</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.679400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.448700</td>\n",
       "      <td>0.532500</td>\n",
       "      <td>0.572600</td>\n",
       "      <td>0.558700</td>\n",
       "      <td>0.777800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.400700</td>\n",
       "      <td>0.572600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.557200</td>\n",
       "      <td>0.646870</td>\n",
       "      <td>0.402000</td>\n",
       "      <td>0.775100</td>\n",
       "      <td>0.352200</td>\n",
       "      <td>0.390600</td>\n",
       "      <td>0.619800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.448700</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>0.576900</td>\n",
       "      <td>0.566100</td>\n",
       "      <td>0.722200</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.402000</td>\n",
       "      <td>0.576900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.515700</td>\n",
       "      <td>0.683120</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>0.800200</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>0.357400</td>\n",
       "      <td>0.714300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>0.503400</td>\n",
       "      <td>0.556400</td>\n",
       "      <td>0.539400</td>\n",
       "      <td>0.788900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>0.556400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>0.656013</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.779500</td>\n",
       "      <td>0.392100</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.698200</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>0.529100</td>\n",
       "      <td>0.587200</td>\n",
       "      <td>0.573400</td>\n",
       "      <td>0.777800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.587200</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>0.668031</td>\n",
       "      <td>0.368500</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>0.353000</td>\n",
       "      <td>0.681100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.440200</td>\n",
       "      <td>0.538500</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>0.554100</td>\n",
       "      <td>0.755600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.368500</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.465700</td>\n",
       "      <td>0.649291</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>0.791200</td>\n",
       "      <td>0.307300</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.451300</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>0.581200</td>\n",
       "      <td>0.567900</td>\n",
       "      <td>0.755600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>0.581200</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.465700</td>\n",
       "      <td>0.669980</td>\n",
       "      <td>0.384500</td>\n",
       "      <td>0.768100</td>\n",
       "      <td>0.338900</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>0.691900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.445300</td>\n",
       "      <td>0.537600</td>\n",
       "      <td>0.573500</td>\n",
       "      <td>0.560600</td>\n",
       "      <td>0.755600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.384500</td>\n",
       "      <td>0.573500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.445200</td>\n",
       "      <td>0.640540</td>\n",
       "      <td>0.400100</td>\n",
       "      <td>0.815800</td>\n",
       "      <td>0.357700</td>\n",
       "      <td>0.387000</td>\n",
       "      <td>0.675900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.462400</td>\n",
       "      <td>0.547000</td>\n",
       "      <td>0.591500</td>\n",
       "      <td>0.576100</td>\n",
       "      <td>0.788900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.400100</td>\n",
       "      <td>0.591500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.431200</td>\n",
       "      <td>0.668744</td>\n",
       "      <td>0.365900</td>\n",
       "      <td>0.794100</td>\n",
       "      <td>0.348400</td>\n",
       "      <td>0.350200</td>\n",
       "      <td>0.648300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.431600</td>\n",
       "      <td>0.526500</td>\n",
       "      <td>0.576100</td>\n",
       "      <td>0.564200</td>\n",
       "      <td>0.733300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.365900</td>\n",
       "      <td>0.576100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.431200</td>\n",
       "      <td>0.661349</td>\n",
       "      <td>0.381000</td>\n",
       "      <td>0.798200</td>\n",
       "      <td>0.383100</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.654400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.431600</td>\n",
       "      <td>0.529900</td>\n",
       "      <td>0.570900</td>\n",
       "      <td>0.558700</td>\n",
       "      <td>0.733300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.381000</td>\n",
       "      <td>0.570900</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.409300</td>\n",
       "      <td>0.656724</td>\n",
       "      <td>0.390200</td>\n",
       "      <td>0.771500</td>\n",
       "      <td>0.386300</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.439300</td>\n",
       "      <td>0.535900</td>\n",
       "      <td>0.577800</td>\n",
       "      <td>0.565100</td>\n",
       "      <td>0.744400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.390200</td>\n",
       "      <td>0.577800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.409300</td>\n",
       "      <td>0.656102</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>0.764900</td>\n",
       "      <td>0.319400</td>\n",
       "      <td>0.359000</td>\n",
       "      <td>0.681800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.433300</td>\n",
       "      <td>0.526500</td>\n",
       "      <td>0.564100</td>\n",
       "      <td>0.548600</td>\n",
       "      <td>0.766700</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>0.564100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.393000</td>\n",
       "      <td>0.654949</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>0.759500</td>\n",
       "      <td>0.394000</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>0.654500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.424800</td>\n",
       "      <td>0.526500</td>\n",
       "      <td>0.572600</td>\n",
       "      <td>0.559600</td>\n",
       "      <td>0.733300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>0.572600</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.381100</td>\n",
       "      <td>0.649787</td>\n",
       "      <td>0.389800</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.399600</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.665200</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.445300</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.574400</td>\n",
       "      <td>0.562400</td>\n",
       "      <td>0.733300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.389800</td>\n",
       "      <td>0.574400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.381100</td>\n",
       "      <td>0.638813</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.383100</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.452100</td>\n",
       "      <td>0.549600</td>\n",
       "      <td>0.582100</td>\n",
       "      <td>0.568800</td>\n",
       "      <td>0.744400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>0.582100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.367600</td>\n",
       "      <td>0.643496</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.759100</td>\n",
       "      <td>0.386700</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>0.577800</td>\n",
       "      <td>0.564200</td>\n",
       "      <td>0.744400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.577800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15150, training_loss=0.6967615692843698, metrics={'train_runtime': 9671.8513, 'train_samples_per_second': 12.495, 'train_steps_per_second': 1.566, 'total_flos': 2.3651518909906944e+19, 'train_loss': 0.6967615692843698, 'epoch': 50.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T05:38:12.417930Z",
     "iopub.status.busy": "2024-11-05T05:38:12.417655Z",
     "iopub.status.idle": "2024-11-05T05:38:26.094602Z",
     "shell.execute_reply": "2024-11-05T05:38:26.093694Z",
     "shell.execute_reply.started": "2024-11-05T05:38:12.417898Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0678befd30e435ba9de122df526399a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating evaluation results...\n",
      "DONE (t=0.24s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.838\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.363\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.442\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.542\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.568\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.586\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.584\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.658\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CocoDetection(img_folder='/kaggle/input/lung-ct-version-n-512/lung_ct_version_n_512.v2i.coco/test', processor=processor)\n",
    "test_dataloader = DataLoader(test_dataset, collate_fn=collate_fn, batch_size=4)\n",
    "# initialize evaluator with ground truth (gt)\n",
    "evaluator = CocoEvaluator(coco_gt=test_dataset.coco, iou_types=[\"bbox\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(\"Running evaluation...\")\n",
    "for idx, batch in enumerate(tqdm(test_dataloader)):\n",
    "    # get the inputs\n",
    "    pixel_values = batch[\"pixel_values\"].to(device)\n",
    "    pixel_mask = batch[\"pixel_mask\"].to(device)\n",
    "    labels = [{k: v.to(device) for k, v in t.items()} for t in batch[\"labels\"]] # these are in DETR format, resized + normalized\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "      outputs = model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "\n",
    "    # turn into a list of dictionaries (one item for each example in the batch)\n",
    "    orig_target_sizes = torch.stack([target[\"orig_size\"] for target in labels], dim=0)\n",
    "    results = processor.post_process_object_detection(outputs, target_sizes=orig_target_sizes, threshold=0)\n",
    "\n",
    "    # provide to metric\n",
    "    # metric expects a list of dictionaries, each item\n",
    "    # containing image_id, category_id, bbox and score keys\n",
    "    predictions = {target['image_id'].item(): output for target, output in zip(labels, results)}\n",
    "    predictions = prepare_for_coco_detection(predictions)\n",
    "    evaluator.update(predictions)\n",
    "\n",
    "evaluator.synchronize_between_processes()\n",
    "evaluator.accumulate()\n",
    "evaluator.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T05:38:26.096129Z",
     "iopub.status.busy": "2024-11-05T05:38:26.095796Z",
     "iopub.status.idle": "2024-11-05T05:39:14.705341Z",
     "shell.execute_reply": "2024-11-05T05:39:14.704175Z",
     "shell.execute_reply.started": "2024-11-05T05:38:26.096097Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/ (stored 0%)\n",
      "  adding: kaggle/working/wandb/ (stored 0%)\n",
      "  adding: kaggle/working/wandb/debug-internal.log (deflated 67%)\n",
      "  adding: kaggle/working/wandb/run-20241105_025707-bzy02g8e/ (stored 0%)\n",
      "  adding: kaggle/working/wandb/run-20241105_025707-bzy02g8e/tmp/ (stored 0%)\n",
      "  adding: kaggle/working/wandb/run-20241105_025707-bzy02g8e/tmp/code/ (stored 0%)\n",
      "  adding: kaggle/working/wandb/run-20241105_025707-bzy02g8e/logs/ (stored 0%)\n",
      "  adding: kaggle/working/wandb/run-20241105_025707-bzy02g8e/logs/debug-internal.log (deflated 67%)\n",
      "  adding: kaggle/working/wandb/run-20241105_025707-bzy02g8e/logs/debug-core.log (deflated 57%)\n",
      "  adding: kaggle/working/wandb/run-20241105_025707-bzy02g8e/logs/debug.log (deflated 69%)\n",
      "  adding: kaggle/working/wandb/run-20241105_025707-bzy02g8e/run-bzy02g8e.wandb (deflated 80%)\n",
      "  adding: kaggle/working/wandb/run-20241105_025707-bzy02g8e/files/ (stored 0%)\n",
      "  adding: kaggle/working/wandb/run-20241105_025707-bzy02g8e/files/requirements.txt (deflated 55%)\n",
      "  adding: kaggle/working/wandb/run-20241105_025707-bzy02g8e/files/output.log (deflated 74%)\n",
      "  adding: kaggle/working/wandb/run-20241105_025707-bzy02g8e/files/wandb-metadata.json (deflated 47%)\n",
      "  adding: kaggle/working/wandb/latest-run/ (stored 0%)\n",
      "  adding: kaggle/working/wandb/latest-run/tmp/ (stored 0%)\n",
      "  adding: kaggle/working/wandb/latest-run/tmp/code/ (stored 0%)\n",
      "  adding: kaggle/working/wandb/latest-run/logs/ (stored 0%)\n",
      "  adding: kaggle/working/wandb/latest-run/logs/debug-internal.log (deflated 67%)\n",
      "  adding: kaggle/working/wandb/latest-run/logs/debug-core.log (deflated 57%)\n",
      "  adding: kaggle/working/wandb/latest-run/logs/debug.log (deflated 69%)\n",
      "  adding: kaggle/working/wandb/latest-run/run-bzy02g8e.wandb (deflated 80%)\n",
      "  adding: kaggle/working/wandb/latest-run/files/ (stored 0%)\n",
      "  adding: kaggle/working/wandb/latest-run/files/requirements.txt (deflated 55%)\n",
      "  adding: kaggle/working/wandb/latest-run/files/output.log (deflated 82%)\n",
      "  adding: kaggle/working/wandb/latest-run/files/wandb-metadata.json (deflated 47%)\n",
      "  adding: kaggle/working/wandb/debug.log (deflated 69%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/ (stored 0%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/runs/ (stored 0%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/runs/Nov05_02-56-48_68cfe757d1fc/ (stored 0%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/runs/Nov05_02-56-48_68cfe757d1fc/events.out.tfevents.1730775420.68cfe757d1fc.30.0 (deflated 70%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-10908/ (stored 0%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-10908/optimizer.pt (deflated 20%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-10908/trainer_state.json (deflated 84%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-10908/model.safetensors (deflated 7%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-10908/rng_state.pth (deflated 25%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-10908/training_args.bin (deflated 51%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-10908/scheduler.pt (deflated 55%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-10908/preprocessor_config.json (deflated 48%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-10908/config.json (deflated 60%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-15150/ (stored 0%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-15150/optimizer.pt (deflated 20%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-15150/trainer_state.json (deflated 85%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-15150/model.safetensors (deflated 7%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-15150/rng_state.pth (deflated 25%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-15150/training_args.bin (deflated 51%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-15150/scheduler.pt (deflated 57%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-15150/preprocessor_config.json (deflated 48%)\n",
      "  adding: kaggle/working/finetune_detr_r50_dc5_version/checkpoint-15150/config.json (deflated 60%)\n",
      "  adding: kaggle/working/=1.4.5 (stored 0%)\n",
      "  adding: kaggle/working/.virtual_documents/ (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r runs.zip /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.model.push_to_hub(\"Toshiiiii1/detr-lung-ct5\")\n",
    "processor.push_to_hub(\"Toshiiiii1/detr-lung-ct5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
